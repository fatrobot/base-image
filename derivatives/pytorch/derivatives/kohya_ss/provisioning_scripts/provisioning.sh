#!/bin/bash

# è„šæœ¬å‡ºé”™æ—¶é€€å‡º
set -eo pipefail

echo "=== SD-Scripts FLUX.1/SD3 Training Environment Setup ==="
echo "Starting provisioning script..."

# è®°å½•å¼€å§‹æ—¶é—´
START_TIME=$(date)
echo "Start time: $START_TIME"

# åˆ‡æ¢åˆ°æŒä¹…åŒ–ç›®å½•
cd /workspace/

# æ›´æ–°ç³»ç»ŸåŒ…å’Œå®‰è£…ç¼–è¯‘å·¥å…·
echo "=== Updating system packages and installing build tools ==="
apt-get update -y
apt-get install -y \
    git \
    wget \
    curl \
    unzip \
    build-essential \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libgoogle-perftools4 \
    libtcmalloc-minimal4 \
    pkg-config \
    libhdf5-dev \
    libffi-dev \
    python3-dev \
    ninja-build \
    cmake

# è®¾ç½®å†…å­˜ä¼˜åŒ–
echo "=== Setting up memory optimization ==="
export LD_PRELOAD=libtcmalloc.so.4:$LD_PRELOAD
echo 'export LD_PRELOAD=libtcmalloc.so.4:$LD_PRELOAD' >> /etc/environment

# éªŒè¯ CUDA çŽ¯å¢ƒ
echo "=== Verifying CUDA environment ==="
nvidia-smi
nvcc --version

# åˆ›å»º Python è™šæ‹ŸçŽ¯å¢ƒ
echo "=== Creating Python virtual environment ==="
python3.10 -m venv sd-scripts-env
source sd-scripts-env/bin/activate

# éªŒè¯ Python ç‰ˆæœ¬
echo "Python version: $(python --version)"
echo "Pip version: $(pip --version)"

# å‡çº§ pip å’ŒåŸºç¡€å·¥å…·
echo "=== Upgrading pip and basic tools ==="
pip install --upgrade pip setuptools wheel

# è®¾ç½® CUDA ç›¸å…³çŽ¯å¢ƒå˜é‡
echo "=== Setting up CUDA environment variables ==="
export CUDA_HOME=/usr/local/cuda
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
export TORCH_CUDA_ARCH_LIST="6.0;6.1;7.0;7.5;8.0;8.6;8.9;9.0"

# å…‹éš† sd-scripts é¡¹ç›® (sd3 åˆ†æ”¯)
echo "=== Cloning sd-scripts repository (sd3 branch) ==="
if [ -d "sd-scripts" ]; then
    echo "sd-scripts directory exists, removing..."
    rm -rf sd-scripts
fi

git clone --branch sd3 --depth 1 https://github.com/kohya-ss/sd-scripts.git
cd sd-scripts

# å®‰è£… PyTorch 2.4.0 with CUDA 12.4 (README æ˜Žç¡®è¦æ±‚)
echo "=== Installing PyTorch 2.4.0 with CUDA 12.4 ==="
pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu124

# éªŒè¯ PyTorch å®‰è£…
echo "=== Verifying PyTorch installation ==="
python -c "import torch; print(f'PyTorch version: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}')"

# å®‰è£… xformers (ä¸Ž PyTorch 2.4.0 å…¼å®¹çš„ç‰ˆæœ¬)
echo "=== Installing xformers for PyTorch 2.4.0 ==="
pip install xformers --index-url https://download.pytorch.org/whl/cu124

# å®‰è£…é¡¹ç›®ä¾èµ– (ä¸¥æ ¼æŒ‰ç…§ requirements.txt)
echo "=== Installing sd-scripts requirements ==="
pip install -r requirements.txt

# éªŒè¯å…³é”®ä¾èµ–ç‰ˆæœ¬
echo "=== Verifying key dependencies versions ==="
python -c "
import accelerate, transformers, diffusers, bitsandbytes, safetensors
print(f'accelerate: {accelerate.__version__}')
print(f'transformers: {transformers.__version__}')
print(f'diffusers: {diffusers.__version__}')
print(f'bitsandbytes: {bitsandbytes.__version__}')
print(f'safetensors: {safetensors.__version__}')
"

# å®‰è£… DeepSpeed (README æ˜Žç¡®è¦æ±‚çš„ç‰ˆæœ¬)
echo "=== Installing DeepSpeed (required for FLUX.1/SD3) ==="
pip install deepspeed==0.16.7

# å®‰è£…é¢å¤–çš„æ€§èƒ½ä¼˜åŒ–åŒ…
echo "=== Installing additional performance packages ==="
pip install --no-deps wandb || echo "wandb installation failed, continuing..."

# å°è¯•å®‰è£… flash-attention (å¯èƒ½å¤±è´¥)
echo "=== Attempting to install flash-attention ==="
pip install flash-attn --no-build-isolation || echo "flash-attn installation failed, this is normal for some environments"

# å°è¯•å®‰è£… triton
echo "=== Attempting to install triton ==="
pip install triton || echo "triton installation failed, continuing..."

# å®‰è£…å¯é€‰çš„ WD14 tagger ä¾èµ–
echo "=== Installing optional WD14 tagger dependencies ==="
pip install onnx==1.15.0 onnxruntime-gpu==1.17.1 || echo "ONNX dependencies installation failed, continuing..."

# åˆ›å»ºä¾¿ç”¨çš„å¯åŠ¨è„šæœ¬
echo "=== Creating convenience scripts ==="
cat > /workspace/activate_env.sh <<'EOF'
#!/bin/bash
source /workspace/sd-scripts-env/bin/activate
cd /workspace/sd-scripts

# è®¾ç½®çŽ¯å¢ƒå˜é‡
export CUDA_HOME=/usr/local/cuda
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
export TORCH_CUDA_ARCH_LIST="6.0;6.1;7.0;7.5;8.0;8.6;8.9;9.0"
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

echo "SD-Scripts environment activated!"
echo "Current directory: $(pwd)"
echo "Python version: $(python --version)"
echo "PyTorch version: $(python -c 'import torch; print(torch.__version__)')"
echo "CUDA available: $(python -c 'import torch; print(torch.cuda.is_available())')"
echo "DeepSpeed available: $(python -c 'try: import deepspeed; print(True); except: print(False)')"

if [ $# -gt 0 ]; then
    exec "$@"
else
    exec bash
fi
EOF

chmod +x /workspace/activate_env.sh

# åˆ›å»ºä¾èµ–æ£€æŸ¥è„šæœ¬
cat > /workspace/check_dependencies.sh <<'EOF'
#!/bin/bash
source /workspace/sd-scripts-env/bin/activate
cd /workspace/sd-scripts

echo "=== Checking SD-Scripts Dependencies ==="
echo "Checking requirements.txt compliance..."

python -c "
import pkg_resources
import sys

# æ£€æŸ¥ requirements.txt ä¸­çš„åŒ…
required_packages = []
with open('requirements.txt', 'r') as f:
    for line in f:
        line = line.strip()
        if line and not line.startswith('#') and not line.startswith('-e'):
            if '==' in line:
                required_packages.append(line)
            elif line == 'tensorboard':
                required_packages.append('tensorboard')

print(f'Checking {len(required_packages)} required packages...')
failed = []
success = []

for package in required_packages:
    try:
        if '==' in package:
            name, version = package.split('==')
            installed = pkg_resources.get_distribution(name)
            if installed.version != version:
                failed.append(f'{name}: required {version}, installed {installed.version}')
            else:
                success.append(package)
        else:
            pkg_resources.get_distribution(package)
            success.append(package)
    except Exception as e:
        failed.append(f'{package}: {str(e)}')

print(f'\\nâœ“ Successfully installed: {len(success)} packages')
if failed:
    print(f'âš  Issues found: {len(failed)} packages')
    for f in failed:
        print(f'  - {f}')
else:
    print('\\nâœ“ All required packages are correctly installed!')

# æ£€æŸ¥é¢å¤–çš„é‡è¦ä¾èµ–
print('\\n=== Additional Dependencies Check ===')
extra_deps = {
    'torch': '2.4.0',
    'torchvision': '0.19.0', 
    'deepspeed': '0.16.7'
}

for name, expected_version in extra_deps.items():
    try:
        installed = pkg_resources.get_distribution(name)
        if installed.version == expected_version:
            print(f'âœ“ {name}: {installed.version} (expected: {expected_version})')
        else:
            print(f'âš  {name}: {installed.version} (expected: {expected_version})')
    except Exception as e:
        print(f'âœ— {name}: {str(e)}')
"
EOF

chmod +x /workspace/check_dependencies.sh

# åˆ›å»ºå®Œæ•´çš„æµ‹è¯•è„šæœ¬
cat > /workspace/test_installation.sh <<'EOF'
#!/bin/bash
source /workspace/sd-scripts-env/bin/activate
cd /workspace/sd-scripts

echo "=== Testing SD-Scripts Installation ==="
echo "1. Testing PyTorch and CUDA..."
python -c "
import torch
print(f'PyTorch version: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'CUDA device count: {torch.cuda.device_count()}')
if torch.cuda.is_available():
    print(f'Current device: {torch.cuda.current_device()}')
    print(f'Device name: {torch.cuda.get_device_name()}')
    print(f'CUDA capability: {torch.cuda.get_device_capability()}')
"

echo "2. Testing core dependencies..."
python -c "
import transformers
import diffusers
import accelerate
import bitsandbytes
import safetensors
import deepspeed
print('âœ“ All core dependencies imported successfully')
print(f'transformers: {transformers.__version__}')
print(f'diffusers: {diffusers.__version__}')
print(f'accelerate: {accelerate.__version__}')
print(f'bitsandbytes: {bitsandbytes.__version__}')
print(f'safetensors: {safetensors.__version__}')
print(f'deepspeed: {deepspeed.__version__}')
"

echo "3. Testing sd-scripts modules..."
python -c "
import sys
sys.path.append('.')
print('Testing basic imports...')
try:
    from library import train_util, model_util
    print('âœ“ SD-Scripts core library imports successful')
except ImportError as e:
    print(f'âœ— Core library import failed: {e}')
    sys.exit(1)

print('Testing FLUX imports...')
try:
    from library import flux_utils, flux_models, flux_train_utils
    print('âœ“ FLUX library imports successful')
except ImportError as e:
    print(f'âš  FLUX library import failed: {e}')

print('Testing SD3 imports...')
try:
    from library import sd3_utils, sd3_models, sd3_train_utils
    print('âœ“ SD3 library imports successful')
except ImportError as e:
    print(f'âš  SD3 library import failed: {e}')
"

echo "4. Testing training scripts availability..."
echo "Available FLUX.1 training scripts:"
ls -la flux_*.py 2>/dev/null || echo "No FLUX scripts found"
echo "Available SD3 training scripts:"
ls -la sd3_*.py 2>/dev/null || echo "No SD3 scripts found"

echo "5. Testing xformers (if available)..."
python -c "
try:
    import xformers
    print(f'âœ“ xformers: {xformers.__version__}')
except ImportError:
    print('âš  xformers not available')
"

echo "6. Testing flash-attention (if available)..."
python -c "
try:
    import flash_attn
    print('âœ“ flash-attention available')
except ImportError:
    print('âš  flash-attention not available (this is normal)')
"

echo "=== Installation test completed ==="
EOF

chmod +x /workspace/test_installation.sh

# åˆ›å»ºä¼˜åŒ–çš„å¯åŠ¨é…ç½®
cat > /workspace/accelerate_config.yaml <<'EOF'
compute_environment: LOCAL_PROCESS
distributed_type: 'NO'
downcast_bf16: 'no'
machine_rank: 0
main_training_function: main
mixed_precision: bf16
num_machines: 1
num_processes: 1
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
EOF

# è®¾ç½®çŽ¯å¢ƒå˜é‡æŒä¹…åŒ–
echo "=== Setting up persistent environment variables ==="
cat >> /etc/environment <<EOF
CUDA_HOME=/usr/local/cuda
PATH=/workspace/sd-scripts-env/bin:/usr/local/cuda/bin:\$PATH
LD_LIBRARY_PATH=/usr/local/cuda/lib64:\$LD_LIBRARY_PATH
PYTHONPATH=/workspace/sd-scripts:\$PYTHONPATH
LD_PRELOAD=libtcmalloc.so.4:\$LD_PRELOAD
TORCH_CUDA_ARCH_LIST="6.0;6.1;7.0;7.5;8.0;8.6;8.9;9.0"
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
HF_HOME=/workspace/.cache/huggingface
EOF

# é…ç½® accelerate
echo "=== Configuring accelerate ==="
source sd-scripts-env/bin/activate
mkdir -p ~/.cache/huggingface/accelerate
cp /workspace/accelerate_config.yaml ~/.cache/huggingface/accelerate/default_config.yaml

# è¿è¡Œä¾èµ–æ£€æŸ¥
echo "=== Running dependency compliance check ==="
/workspace/check_dependencies.sh

# è¿è¡Œå®‰è£…æµ‹è¯•
echo "=== Running installation test ==="
/workspace/test_installation.sh

# åˆ›å»ºå¿«é€Ÿè®­ç»ƒç¤ºä¾‹è„šæœ¬
cat > /workspace/quick_test_training.sh <<'EOF'
#!/bin/bash
source /workspace/sd-scripts-env/bin/activate
cd /workspace/sd-scripts

echo "=== Quick Training Test ==="
echo "Testing FLUX.1 training script..."
python flux_train_network.py --help | head -20

echo "Testing SD3 training script..."
python sd3_train_network.py --help | head -20

echo "Testing inference script..."
python flux_minimal_inference.py --help | head -20

echo "âœ“ All training scripts are accessible"
EOF

chmod +x /workspace/quick_test_training.sh

# æ˜¾ç¤ºä½¿ç”¨è¯´æ˜Ž
echo "=== Setup completed successfully! ==="
echo ""
echo "ðŸŽ¯ Environment Summary:"
echo "  - Python: $(python --version)"
echo "  - PyTorch: $(python -c 'import torch; print(torch.__version__)')"
echo "  - CUDA Available: $(python -c 'import torch; print(torch.cuda.is_available())')"
echo "  - DeepSpeed: $(python -c 'try: import deepspeed; print(deepspeed.__version__); except: print("Not available")')"
echo ""
echo "ðŸ“‹ Usage Instructions:"
echo "1. Activate environment: source /workspace/activate_env.sh"
echo "2. Check dependencies: /workspace/check_dependencies.sh"
echo "3. Test installation: /workspace/test_installation.sh"
echo "4. Quick training test: /workspace/quick_test_training.sh"
echo ""
echo "ðŸš€ Key Training Scripts:"
echo "  FLUX.1 LoRA:     flux_train_network.py"
echo "  FLUX.1 Full:     flux_train.py"
echo "  SD3 LoRA:        sd3_train_network.py"
echo "  SD3 Full:        sd3_train.py"
echo "  Inference:       flux_minimal_inference.py, sd3_minimal_inference.py"
echo ""
echo "ðŸ’¡ Performance Tips:"
echo "  - Use --blocks_to_swap for lower VRAM usage"
echo "  - DeepSpeed is required for FLUX.1 ControlNet training"
echo "  - Batch size 1 recommended for 24GB VRAM"
echo ""
echo "ðŸ”§ Environment Details:"
echo "  - Virtual env: /workspace/sd-scripts-env/"
echo "  - Scripts: /workspace/sd-scripts/"
echo "  - Accelerate config: ~/.cache/huggingface/accelerate/default_config.yaml"
echo ""

# è®°å½•ç»“æŸæ—¶é—´
END_TIME=$(date)
echo "â±ï¸  Timing Summary:"
echo "  Start time: $START_TIME"
echo "  End time: $END_TIME"
echo ""
echo "âœ… SD-Scripts FLUX.1/SD3 environment setup completed successfully!"
echo "ðŸŽ‰ Ready for training!"
